{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c5919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "from threading import Thread\n",
    "import playsound\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a17bf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACE_DOWNSAMPLE_RATIO = 1.5\n",
    "RESIZE_HEIGHT = 460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129e0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.27\n",
    "modelPath = \"shape_predictor_70_face_landmarks.dat\"\n",
    "sound_path = \"alarm.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e4a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70eca9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = dlib.shape_predictor(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381865cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftEyeIndex = [36, 37, 38, 39, 40, 41]\n",
    "rightEyeIndex = [42, 43, 44, 45, 46, 47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b601f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "blinkCount = 0\n",
    "drowsy = 0\n",
    "state = 0\n",
    "blinkTime = 0.15 #150ms\n",
    "drowsyTime = 1.5  #1200ms\n",
    "ALARM_ON = False\n",
    "GAMMA = 1.5\n",
    "threadStatusQ = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a370682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "invGamma = 1.0/GAMMA\n",
    "table = np.array([((i / 255.0) ** invGamma) * 255 for i in range(0, 256)]).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bae73b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_correction(image):\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29eefe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.equalizeHist(gray) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5b26311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soundAlert(path, threadStatusQ):\n",
    "    while True:\n",
    "        if not threadStatusQ.empty():\n",
    "            FINISHED = threadStatusQ.get()\n",
    "            if FINISHED:\n",
    "                break\n",
    "        playsound.playsound(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0b8bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b07db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkEyeStatus(landmarks):\n",
    "    mask = np.zeros(frame.shape[:2], dtype = np.float32)\n",
    "    hullLeftEye = []\n",
    "    \n",
    "    for i in range(0, len(leftEyeIndex)):\n",
    "        hullLeftEye.append((landmarks[leftEyeIndex[i]][0], landmarks[leftEyeIndex[i]][1]))\n",
    "    cv2.fillConvexPoly(mask, np.int32(hullLeftEye), 255)\n",
    "    \n",
    "    hullRightEye = []\n",
    "    \n",
    "    for i in range(0, len(rightEyeIndex)):\n",
    "        hullRightEye.append((landmarks[rightEyeIndex[i]][0], landmarks[rightEyeIndex[i]][1]))\n",
    "    \n",
    "    cv2.fillConvexPoly(mask, np.int32(hullRightEye), 255)\n",
    "    leftEAR = eye_aspect_ratio(hullLeftEye)\n",
    "    rightEAR = eye_aspect_ratio(hullRightEye)\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "    eyeStatus = 1\n",
    "    \n",
    "    if (ear < thresh):\n",
    "        eyeStatus = 0\n",
    "        \n",
    "    return eyeStatus  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c778a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkBlinkStatus(eyeStatus):\n",
    "    global state, blinkCount, drowsy\n",
    "    if(state >= 0 and state <= falseBlinkLimit):\n",
    "        if(eyeStatus):\n",
    "            state = 0\n",
    "\n",
    "        else:\n",
    "            state += 1\n",
    "\n",
    "    elif(state >= falseBlinkLimit and state < drowsyLimit):\n",
    "        if(eyeStatus):\n",
    "            blinkCount += 1 \n",
    "            state = 0\n",
    "\n",
    "        else:\n",
    "            state += 1\n",
    "\n",
    "    else:\n",
    "        if(eyeStatus):\n",
    "            state = 0\n",
    "            drowsy = 1\n",
    "            blinkCount += 1\n",
    "\n",
    "        else:\n",
    "            drowsy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbb771ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLandmarks(im):\n",
    "    imSmall = cv2.resize(im, None, \n",
    "                            fx = 1.0/FACE_DOWNSAMPLE_RATIO, \n",
    "                            fy = 1.0/FACE_DOWNSAMPLE_RATIO, \n",
    "                            interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    rects = detector(imSmall, 0)\n",
    "    if len(rects) == 0:\n",
    "        return 0\n",
    "\n",
    "    newRect = dlib.rectangle(int(rects[0].left() * FACE_DOWNSAMPLE_RATIO),\n",
    "                            int(rects[0].top() * FACE_DOWNSAMPLE_RATIO),\n",
    "                            int(rects[0].right() * FACE_DOWNSAMPLE_RATIO),\n",
    "                            int(rects[0].bottom() * FACE_DOWNSAMPLE_RATIO))\n",
    "\n",
    "    points = []\n",
    "    [points.append((p.x, p.y)) for p in predictor(im, newRect).parts()]\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "184229dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caliberation in Progress!\n",
      "Caliberation Complete!\n",
      "Current SPF (seconds per frame) is 34.59 ms\n",
      "drowsy limit: 43.36479827628632, false blink limit: 4.336479827628632\n"
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "for i in range(10):\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "totalTime = 0.0\n",
    "validFrames = 0\n",
    "dummyFrames = 100\n",
    "\n",
    "print(\"Caliberation in Progress!\")\n",
    "while(validFrames < dummyFrames):\n",
    "    validFrames += 1\n",
    "    t = time.time()\n",
    "    ret, frame = capture.read()\n",
    "    height, width = frame.shape[:2]\n",
    "    IMAGE_RESIZE = np.float32(height)/RESIZE_HEIGHT\n",
    "    frame = cv2.resize(frame, None, \n",
    "                        fx = 1/IMAGE_RESIZE, \n",
    "                        fy = 1/IMAGE_RESIZE, \n",
    "                        interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    # adjusted = gamma_correction(frame)\n",
    "    adjusted = histogram_equalization(frame)\n",
    "\n",
    "    landmarks = getLandmarks(adjusted)\n",
    "    timeLandmarks = time.time() - t\n",
    "\n",
    "    if landmarks == 0:\n",
    "        validFrames -= 1\n",
    "        cv2.putText(frame, \"Unable to detect face, Please check proper lighting\", (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, \"or decrease FACE_DOWNSAMPLE_RATIO\", (10, 50), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            sys.exit()\n",
    "\n",
    "    else:\n",
    "        totalTime += timeLandmarks\n",
    "        # cv2.putText(frame, \"Caliberation in Progress\", (200, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        # cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "        \n",
    "    # if cv2.waitKey(1) & 0xFF == 27:\n",
    "    #         sys.exit()\n",
    "\n",
    "print(\"Caliberation Complete!\")\n",
    "\n",
    "spf = totalTime/dummyFrames\n",
    "print(\"Current SPF (seconds per frame) is {:.2f} ms\".format(spf * 1000))\n",
    "\n",
    "drowsyLimit = drowsyTime/spf\n",
    "falseBlinkLimit = blinkTime/spf\n",
    "print(\"drowsy limit: {}, false blink limit: {}\".format(drowsyLimit, falseBlinkLimit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daf94172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 259 for command:\n",
      "        play alarm.wav wait\n",
      "    The driver cannot recognize the specified command parameter.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: alarm.wav\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MUSHKAN\\anaconda3\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\MUSHKAN\\anaconda3\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-11-7f5ce066713a>\", line 7, in soundAlert\n",
      "  File \"C:\\Users\\MUSHKAN\\anaconda3\\lib\\site-packages\\playsound.py\", line 73, in _playsoundWin\n",
      "    winCommand(u'play {}{}'.format(sound, ' wait' if block else ''))\n",
      "  File \"C:\\Users\\MUSHKAN\\anaconda3\\lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 259 for command:\n",
      "        play alarm.wav wait\n",
      "    The driver cannot recognize the specified command parameter.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    vid_writer = cv2.VideoWriter('output-low-light-2.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame.shape[1],frame.shape[0]))\n",
    "    while(1):\n",
    "        try:\n",
    "            t = time.time()\n",
    "            ret, frame = capture.read()\n",
    "            height, width = frame.shape[:2]\n",
    "            IMAGE_RESIZE = np.float32(height)/RESIZE_HEIGHT\n",
    "            frame = cv2.resize(frame, None, \n",
    "                                fx = 1/IMAGE_RESIZE, \n",
    "                                fy = 1/IMAGE_RESIZE, \n",
    "                                interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "            # adjusted = gamma_correction(frame)\n",
    "            adjusted = histogram_equalization(frame)\n",
    "\n",
    "            landmarks = getLandmarks(adjusted)\n",
    "            if landmarks == 0:\n",
    "                validFrames -= 1\n",
    "                cv2.putText(frame, \"Unable to detect face, Please check proper lighting\", (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, \"or decrease FACE_DOWNSAMPLE_RATIO\", (10, 50), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == 27:\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "            eyeStatus = checkEyeStatus(landmarks)\n",
    "            checkBlinkStatus(eyeStatus)\n",
    "\n",
    "            for i in range(0, len(leftEyeIndex)):\n",
    "                cv2.circle(frame, (landmarks[leftEyeIndex[i]][0], landmarks[leftEyeIndex[i]][1]), 1, (0, 0, 255), -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            for i in range(0, len(rightEyeIndex)):\n",
    "                cv2.circle(frame, (landmarks[rightEyeIndex[i]][0], landmarks[rightEyeIndex[i]][1]), 1, (0, 0, 255), -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            if drowsy:\n",
    "                cv2.putText(frame, \"! ! ! DROWSINESS ALERT ! ! !\", (70, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                if not ALARM_ON:\n",
    "                    ALARM_ON = True\n",
    "                    threadStatusQ.put(not ALARM_ON)\n",
    "                    thread = Thread(target=soundAlert, args=(sound_path, threadStatusQ,))\n",
    "                    thread.setDaemon(True)\n",
    "                    thread.start()\n",
    "\n",
    "            else:\n",
    "                cv2.putText(frame, \"Blinks : {}\".format(blinkCount), (460, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2, cv2.LINE_AA)\n",
    "                # (0, 400)\n",
    "                ALARM_ON = False\n",
    "\n",
    "\n",
    "            cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "            vid_writer.write(frame)\n",
    "\n",
    "            k = cv2.waitKey(1) \n",
    "            if k == ord('r'):\n",
    "                state = 0\n",
    "                drowsy = 0\n",
    "                ALARM_ON = False\n",
    "                threadStatusQ.put(not ALARM_ON)\n",
    "\n",
    "            elif k == 27:\n",
    "                break\n",
    "\n",
    "            # print(\"Time taken\", time.time() - t)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    capture.release()\n",
    "    vid_writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78439357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9f72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
